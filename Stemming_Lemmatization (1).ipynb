{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessary libraries\n"
      ],
      "metadata": {
        "id": "ii9sd-Nn_TTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kefuBJo50Oez",
        "outputId": "35f0ad78-8522-479f-e657-4aaa48225707"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag, word_tokenize\n"
      ],
      "metadata": {
        "id": "UMvRNmdk_Wng"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading necessary NLTK resources\n"
      ],
      "metadata": {
        "id": "FeOOYe46_YWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "L3KxSNJj_WjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623004d8-0157-49c8-92cb-44ceb3edf2a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample text"
      ],
      "metadata": {
        "id": "DXNU9Vic_apO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The leaves on the trees are falling. The children are playing with leaves in the park.\"\n"
      ],
      "metadata": {
        "id": "F_5JHYrp_WgO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing the text into words\n"
      ],
      "metadata": {
        "id": "zoFDGkGn_cVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(text)\n"
      ],
      "metadata": {
        "id": "vVcVhtNo_WaO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Stemming\n"
      ],
      "metadata": {
        "id": "TIXusxPl_ecC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we add the line stemmer.stem(word)\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(\"Stemmed Words: \", stemmed_words)"
      ],
      "metadata": {
        "id": "puov6nZD_WWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96488758-8cdd-46fa-e663-79c4da768874"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Words:  ['the', 'leav', 'on', 'the', 'tree', 'are', 'fall', '.', 'the', 'children', 'are', 'play', 'with', 'leav', 'in', 'the', 'park', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Lemmatization\n"
      ],
      "metadata": {
        "id": "gjDs9Pmc_gTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "dsqyCAUr_i3f"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to get part of speech tags compatible with WordNet\n"
      ],
      "metadata": {
        "id": "5t24WQ99_ksc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(word):\n",
        "    tag = pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "metadata": {
        "id": "kgDD2hM__mhG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in words]\n",
        "print(\"Lemmatized Words: \", lemmatized_words)"
      ],
      "metadata": {
        "id": "6SgHxLJJ_tI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ccdd99c-7cf0-43d3-99a5-f706ccc0d817"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Words:  ['The', 'leaf', 'on', 'the', 'tree', 'be', 'fall', '.', 'The', 'child', 'be', 'play', 'with', 'leaf', 'in', 'the', 'park', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare original, stemmed, and lemmatized words\n"
      ],
      "metadata": {
        "id": "-ry54fxp_vfj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gtKW6Vk4_Km2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a324fb2b-e2ca-4100-c852-cf4f8a7355ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison (Original, Stemmed, Lemmatized):\n",
            "The             -> the             -> The            \n",
            "leaves          -> leav            -> leaf           \n",
            "on              -> on              -> on             \n",
            "the             -> the             -> the            \n",
            "trees           -> tree            -> tree           \n",
            "are             -> are             -> be             \n",
            "falling         -> fall            -> fall           \n",
            ".               -> .               -> .              \n",
            "The             -> the             -> The            \n",
            "children        -> children        -> child          \n",
            "are             -> are             -> be             \n",
            "playing         -> play            -> play           \n",
            "with            -> with            -> with           \n",
            "leaves          -> leav            -> leaf           \n",
            "in              -> in              -> in             \n",
            "the             -> the             -> the            \n",
            "park            -> park            -> park           \n",
            ".               -> .               -> .              \n"
          ]
        }
      ],
      "source": [
        "comparison = list(zip(words, stemmed_words, lemmatized_words))\n",
        "print(\"\\nComparison (Original, Stemmed, Lemmatized):\")\n",
        "for original, stemmed, lemmatized in comparison:\n",
        "    print(f\"{original:15} -> {stemmed:15} -> {lemmatized:15}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import PorterStemmer\n"
      ],
      "metadata": {
        "id": "JzVXuFXr_yVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n"
      ],
      "metadata": {
        "id": "E3VD3gwV_4pi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List of words to stem\n"
      ],
      "metadata": {
        "id": "vN9xnoxH_5me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"running\", \"jumps\", \"easily\", \"flying\"]\n"
      ],
      "metadata": {
        "id": "H0F65z_a_7GW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the stemmer"
      ],
      "metadata": {
        "id": "V3TrYFTr_9G8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n"
      ],
      "metadata": {
        "id": "JDAQYVcq_83z"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Stem each word and print the result\n"
      ],
      "metadata": {
        "id": "9gbg_-WF__cW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "print(\"Stemmed Words:\", stemmed_words)\n"
      ],
      "metadata": {
        "id": "n3ByrzKu_VAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe17e5eb-9439-4611-8252-3c2ce4b82679"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Words: ['run', 'jump', 'easili', 'fli']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import WordNetLemmatizer and other necessary modules\n"
      ],
      "metadata": {
        "id": "9v_oNGh8ABmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag\n"
      ],
      "metadata": {
        "id": "FK5TnQicAGK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List of words to lemmatize\n"
      ],
      "metadata": {
        "id": "gqykQJbXAG7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"running\", \"jumps\", \"easily\", \"flying\"]\n"
      ],
      "metadata": {
        "id": "EhavRpJLAHzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the lemmatizer\n"
      ],
      "metadata": {
        "id": "JYJ0jgB_AIym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n"
      ],
      "metadata": {
        "id": "tNAQ7KTcAJtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper function to get WordNet PoS tag\n"
      ],
      "metadata": {
        "id": "svvQAi75AKWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(word):\n",
        "    tag = pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "metadata": {
        "id": "gV61RG-3ALb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Lemmatize each word with PoS tag and print the result\n"
      ],
      "metadata": {
        "id": "8XXYt1N_ANNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we add the line lemmatizer.lemmatize(word,get_wordnet_pos(word)\n",
        "lemmatized_words = [lemmatizer.lemmatize(word,get_wordnet_pos(word)) for word in words]\n",
        "\n",
        "print(\"Lemmatized Words:\", lemmatized_words)\n"
      ],
      "metadata": {
        "id": "RLuE1fcyAEBW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}